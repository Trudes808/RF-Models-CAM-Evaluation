{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fft score cam implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pickle\n",
    "#from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import transform\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from plotting_utils import RF_Visualizer\n",
    "import pandas as pd\n",
    "from scipy.fft import fft, ifft,fftshift\n",
    "import os\n",
    "import math\n",
    "from scipy import signal\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "print(cur_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from model import Baseline_CNN1D\n",
    "    from dataset_tprime import TPrimeDataset\n",
    "    import argparse\n",
    "    from scipy.io import loadmat\n",
    "\n",
    "\n",
    "    # seqs = {}\n",
    "    # with open(\"/home/sagetrudeau/Datasets/ORACLE/mat_files/raw/train.pkl\", \"rb\") as f:#Oracle\n",
    "    # #with open(\"/raid/backup_storage_oldDGX/LORA/Year_1_outdoor/outdoor_dataset_1/mat_files/raw/train.pkl\", \"rb\") as f:\n",
    "    #     file_dict = pickle.load(f)\n",
    "    # filenames = file_dict[\"files\"]\n",
    "    # print(filenames)\n",
    "    # for i, name in enumerate(filenames):\n",
    "    #     #print(i, len(filenames))\n",
    "    #     seqs[name] = loadmat(name)[\"f_sig\"][0]\n",
    "    # #dataset = InDistributionTestDataset(seqs,\"val\")\n",
    "    # dataset = InDistributionTestDatasetContinuous(seqs, \"val\")\n",
    "    # #dataset = InDistributionTrainDataset(seqs)\n",
    "    # train_dataset = InDistributionTrainDataset(seqs)\n",
    "    # del seqs\n",
    "    args=argparse.Namespace()\n",
    "    args.protocols = ['802_11ax', '802_11b_upsampled', '802_11n', '802_11g']\n",
    "    args.noise = True\n",
    "    args.snr_db = [30]\n",
    "    args.raw_path = \"/home/sagetrudeau/Projects/t-prime/data/DATASET1_1\"\n",
    "    args.slicelen = 512\n",
    "    args.overlap_ratio = 0.0\n",
    "    args.postfix = ''\n",
    "    args.raw_data_ratio = 1.0\n",
    "    args.channel = None\n",
    "    args.out_mode = 'real'\n",
    "    args.worker_batch_size = 512\n",
    "\n",
    "    ds_test = TPrimeDataset(args.protocols,\n",
    "                          ds_path=args.raw_path,\n",
    "                          ds_type='test',\n",
    "                          snr_dbs=args.snr_db,\n",
    "                          slice_len=args.slicelen,\n",
    "                          slice_overlap_ratio=float(args.overlap_ratio),\n",
    "                          raw_data_ratio=args.raw_data_ratio,\n",
    "                          file_postfix=args.postfix,\n",
    "                          override_gen_map=False,    # it will use the same as above call\n",
    "                          apply_wchannel=args.channel,\n",
    "                          apply_noise=args.noise,\n",
    "                          out_mode=args.out_mode)\n",
    "    dataloader = DataLoader(ds_test, batch_size=args.worker_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#t-prime\n",
    "PATH = './results/t-prime/SNR30/'\n",
    "Nclass = 4\n",
    "num_channels = 2\n",
    "num_feats = 1\n",
    "slice_len = 512\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "model = Baseline_CNN1D(classes=Nclass, numChannels=num_channels, slice_len=slice_len)\n",
    "checkpoint = torch.load(cur_dir+\"/model/model.baseline_cnn1d.nochan.range.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device) # reload the model on the appropriate device\n",
    "model.device = device\n",
    "model.eval()    # set the evaluation mode\n",
    "print(model,next(model.parameters()).device)\n",
    "print(model.device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import itertools\n",
    "import cuml\n",
    "# Function to extract features from the last fully connected layer before softmax\n",
    "def extract_features(model, data_loader):\n",
    "    features = []\n",
    "    labels = []\n",
    "    samples_to_run=5\n",
    "    i=0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            # Ensure data is converted to float and moved to the correct device\n",
    "            data = data.float().to(model.device)  # Convert data to float here\n",
    "            # Get the output from the last fully connected layer (fc1)\n",
    "            x = model.conv1(data)\n",
    "            x = model.relu1(x)\n",
    "            x = model.maxpool1(x)\n",
    "            x = model.conv2(x)\n",
    "            x = model.relu2(x)\n",
    "            x = model.maxpool2(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = model.fc1(x)\n",
    "            x = model.relu3(x)\n",
    "            # x= model.fc2(x)\n",
    "            # x=model.logSoftmax(x)\n",
    "            features.append(x.cpu().numpy())\n",
    "            labels.append(target.numpy())\n",
    "            if i > samples_to_run:\n",
    "                break\n",
    "            i+=1\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "features, labels = extract_features(model, dataloader)\n",
    "print(features.shape,labels.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20,7), constrained_layout=True)\n",
    "for c, per in zip(itertools.count(), [5, 30, 50]):\n",
    "    tsne = cuml.manifold.TSNE(n_components=2,\n",
    "                perplexity=per,\n",
    "                n_neighbors=per*4)\n",
    "    tsne = tsne.fit_transform(features)\n",
    "    scatter = ax[c].scatter(tsne[:-1, 0], tsne[:-1, 1], c=labels[:-1], cmap='tab10', s=0.3)\n",
    "    scatter = ax[c].scatter(tsne[-1, 0], tsne[-1, 1], c=labels[-1], cmap='tab10',marker='*', edgecolors='k', s=50)\n",
    "    ax[c].set_title(f'Perplexity: {per}', fontsize=16)    \n",
    "\n",
    "fig.suptitle('t-SNE Dimensionality reduction', fontweight='bold', fontsize=25)\n",
    "cbar = fig.colorbar(scatter, boundaries=np.arange(11)-0.5, location='right')\n",
    "cbar.set_ticks(np.arange(10))\n",
    "cbar.set_ticklabels(np.arange(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to augment the last sample in the dataloader by replacing it with noise of equal power\n",
    "def augment_sample(model, dataloader):\n",
    "    # Access the dataset directly from the dataloader\n",
    "    dataset = dataloader.dataset\n",
    "    print(type(dataset))\n",
    "    last_index = len(dataset) - 1\n",
    "    last_index = 10000\n",
    "\n",
    "    # Extract the last input and label\n",
    "    inputs, labels = dataset[last_index]\n",
    "    aug_inputs = inputs.copy()\n",
    "\n",
    "    # Print the shape and values of the inputs\n",
    "    print(\"Original numpy array values:\")\n",
    "    print(inputs)\n",
    "    print(f\"Shape of inputs: {inputs.shape}\")\n",
    "\n",
    "    # Convert numpy array to torch tensor\n",
    "    slice_of_trans = torch.from_numpy(inputs).float()\n",
    "\n",
    "    # Check the device of the model\n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"Model is on device: {device}\")\n",
    "\n",
    "    # Move the tensor to the same device as the model\n",
    "    slice_of_trans = slice_of_trans.to(device)\n",
    "\n",
    "    # Ensure the input shape matches the model's expected dimensions\n",
    "    if len(slice_of_trans.shape) == 2:\n",
    "        slice_of_trans = slice_of_trans.unsqueeze(0)\n",
    "    print(\"og\",slice_of_trans)\n",
    "    # Run the model prediction\n",
    "    original_outputs = model(slice_of_trans).detach().cpu().numpy()\n",
    "    print(f\"Original outputs shape: {original_outputs.shape}\")\n",
    "    print(f\"Original prediction: {original_outputs}\")\n",
    "    print(f\"True label: {labels}\")\n",
    "\n",
    "    # Grab the slice and calculate the power of the original signal\n",
    "    complex_slice = inputs[0] + 1j * inputs[1]\n",
    "    total_power_original = np.sum(np.abs(complex_slice)**2)\n",
    "    #total_power_original = 513.93585\n",
    "    print(\"power target\",total_power_original)\n",
    "\n",
    "    # Generate a noise array with the same length as the original sample\n",
    "    slice_len = complex_slice.shape\n",
    "    noise_array = np.random.normal(size=slice_len) + 1j * np.random.normal(size=slice_len)\n",
    "    total_power_noise = np.sum(np.abs(noise_array)**2)\n",
    "\n",
    "    # Scale the noise array to match the total power of the original signal\n",
    "    scaling_factor = np.sqrt(total_power_original / total_power_noise)\n",
    "    equal_power_noise = noise_array * scaling_factor\n",
    "\n",
    "    # Replace the last sample with the equal power noise\n",
    "    real_part = np.real(equal_power_noise)\n",
    "    imaginary_part = np.imag(equal_power_noise)\n",
    "    # Update the inputs with the modified slice\n",
    "    aug_inputs[0]= real_part\n",
    "    aug_inputs[1] = imaginary_part\n",
    "\n",
    "    # aug_slice_of_trans = torch.from_numpy([real_part,imaginary_part]).float()\n",
    "    # aug_slice_of_trans = aug_slice_of_trans.to(device)\n",
    "  \n",
    "\n",
    "    # Run predictions after augmentation for verification\n",
    "    aug_slice_of_trans = torch.from_numpy(aug_inputs).float()\n",
    "    aug_slice_of_trans = aug_slice_of_trans.to(device)\n",
    "    if len(aug_slice_of_trans.shape) == 2:\n",
    "        aug_slice_of_trans = aug_slice_of_trans.unsqueeze(0)\n",
    "    print(\"augmented\",aug_slice_of_trans)\n",
    "    augmented_outputs = model(aug_slice_of_trans).detach().cpu().numpy()\n",
    "    original_prediction = np.argmax(original_outputs, axis=1)[-1]\n",
    "    augmented_prediction = np.argmax(augmented_outputs, axis=1)[-1]\n",
    "    # Print the shape and values of the inputs\n",
    "    print(\"Augmented numpy array values:\")\n",
    "    print(aug_inputs)\n",
    "    print(f\"Shape of inputs: {aug_inputs.shape}\")\n",
    "\n",
    "    print(f\"Augmented output: {augmented_outputs}\")\n",
    "    print(\"Original prediction:\", original_prediction)\n",
    "    print(\"Augmented prediction:\", augmented_prediction)\n",
    "\n",
    "    # Update the dataset with the modified \n",
    "    #dataset = list(dataset)\n",
    "    \n",
    "    dataset.augment_signal_cache_item(last_index, aug_inputs)\n",
    "    check_input, label = dataset[last_index]\n",
    "    print(check_input)\n",
    "    # Create a new dataloader with the modified dataset\n",
    "    #new_dataloader = DataLoader(dataset, batch_size=dataloader.batch_size, shuffle=False)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "# Function to plot t-SNE with and without augmentation\n",
    "def plot_tsne_with_augmentation(model, dataloader):\n",
    "    # Extract features and labels from the original data\n",
    "    features, labels = extract_features(model, dataloader)\n",
    "    print(\"Original features shape:\", features.shape, \"Labels shape:\", labels.shape)\n",
    "\n",
    "    # Augment the last sample in the dataloader\n",
    "    augmented_dataloader = augment_sample(model,dataloader)\n",
    "\n",
    "    # Extract features and labels from the augmented data\n",
    "    augmented_features, augmented_labels = extract_features(model, augmented_dataloader)\n",
    "    print(\"Augmented features shape:\", augmented_features.shape, \"Labels shape:\", augmented_labels.shape)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(20, 14), constrained_layout=True)\n",
    "    \n",
    "    for c, per in zip(itertools.count(), [5, 30, 50]):\n",
    "        # Original t-SNE\n",
    "        tsne = cuml.manifold.TSNE(n_components=2, perplexity=per, n_neighbors=per*4)\n",
    "        tsne_result = tsne.fit_transform(features)\n",
    "        scatter = ax[0, c].scatter(tsne_result[:-1, 0], tsne_result[:-1, 1], c=labels[:-1], cmap='tab10', s=0.3)\n",
    "        scatter = ax[0, c].scatter(tsne_result[-1, 0], tsne_result[-1, 1], c=labels[-1], cmap='tab10', marker='*', edgecolors='k', s=50)\n",
    "        ax[0, c].set_title(f'Original - Perplexity: {per}', fontsize=16)\n",
    "        \n",
    "        # Augmented t-SNE\n",
    "        tsne_augmented = cuml.manifold.TSNE(n_components=2, perplexity=per, n_neighbors=per*4)\n",
    "        tsne_augmented_result = tsne_augmented.fit_transform(augmented_features)\n",
    "        scatter = ax[1, c].scatter(tsne_augmented_result[:-1, 0], tsne_augmented_result[:-1, 1], c=augmented_labels[:-1], cmap='tab10', s=0.3)\n",
    "        scatter = ax[1, c].scatter(tsne_augmented_result[-1, 0], tsne_augmented_result[-1, 1], c=augmented_labels[-1], cmap='tab10', marker='*', edgecolors='k', s=50)\n",
    "        ax[1, c].set_title(f'Augmented - Perplexity: {per}', fontsize=16)\n",
    "    \n",
    "    fig.suptitle('t-SNE Dimensionality Reduction Before and After Augmentation', fontweight='bold', fontsize=25)\n",
    "    cbar = fig.colorbar(scatter, boundaries=np.arange(11)-0.5, location='right')\n",
    "    cbar.set_ticks(np.arange(10))\n",
    "    cbar.set_ticklabels(np.arange(10))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_tsne_with_augmentation(model, dataloader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woods_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
