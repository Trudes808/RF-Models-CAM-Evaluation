{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook of test_runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_CNN1D(\n",
      "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (feature_extractor): ModuleList(\n",
      "    (0): Conv1d(2, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=16000, out_features=256, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (logSoftmax): LogSoftmax(dim=1)\n",
      ") cpu\n",
      "cpu\n",
      "(array([[ 0.83196074, -0.65662307,  0.32264539, ..., -0.65761225,\n",
      "        -1.12059288, -0.67295217],\n",
      "       [ 0.50358201,  1.13937468, -0.01223459, ..., -1.17871891,\n",
      "         0.24539864, -0.60937985]]), 3)\n",
      "before: (array([[ 0.81132933, -0.63675798,  0.37472535, ..., -0.62718062,\n",
      "        -1.14127198, -0.69151958],\n",
      "       [ 0.53602555,  1.14550241, -0.02265885, ..., -1.2032766 ,\n",
      "         0.18458702, -0.62754989]]), 3)\n",
      "after: (array([[-0.52137242, -0.13405444,  1.3748105 , ...,  0.48236295,\n",
      "         0.01070001, -0.48832041],\n",
      "       [ 0.17765115,  0.58634318, -0.25150361, ..., -0.63804123,\n",
      "         0.64191   ,  0.47817152]]), 3)\n",
      "Aug outputs shape: (1, 4)\n",
      "Aug prediction: [[  0.       -18.15188  -17.701477 -49.16118 ]]\n",
      "Running layer: norm LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "Running layer: conv1 Conv1d(2, 64, kernel_size=(7,), stride=(1,))\n",
      "Running layer: relu1 ReLU()\n",
      "Running layer: maxpool1 MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Running layer: conv2 Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "Running layer: relu2 ReLU()\n",
      "Running layer: maxpool2 MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Running layer: feature_extractor ModuleList(\n",
      "  (0): Conv1d(2, 64, kernel_size=(7,), stride=(1,))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Running layer: fc1 Linear(in_features=16000, out_features=256, bias=True)\n",
      "Running layer: relu3 ReLU()\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from model_loader import load_pretrained_model, load_dataloader\n",
    "from augmentations import DataAugmentationTesting\n",
    "from embeddings_similarity_module import EmbeddingSimilarityModule\n",
    "#from cam_module import ClassActivationMapping\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Create a logger object\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)  # Set the minimum level of messages to log\n",
    "\n",
    "# Create a file handler that logs debug and higher level messages\n",
    "file_handler = logging.FileHandler('example.log', mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Create a console handler that logs debug and higher level messages\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# Add both handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        return json.load(config_file)\n",
    "\n",
    "def save_test_results(results):\n",
    "    # Implement the logic to save results to a file or database\n",
    "    pass\n",
    "\n",
    "def print_summary(results):\n",
    "    # Summarize test results\n",
    "    print(\"Test Summary:\")\n",
    "    for result in results:\n",
    "        print(f\"Index: {result['index']}, Model Output: {result['output']}, Embedding Similarity: {result['embedding_similarity']}, CAM Result: {result['cam_result']}\")\n",
    "\n",
    "#***************************************************      Main           *************************************************************\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    config_path = \"config.json\"\n",
    "    config = load_config(config_path)\n",
    "    model = load_pretrained_model(config)\n",
    "    logging.info(\"Model Loaded\")\n",
    "    dataloader = load_dataloader(config)\n",
    "    logging.info(\"Dataloader Loaded\")\n",
    "\n",
    "    # Initialize the Data Augmentation Module\n",
    "    augmentor_sandbox = DataAugmentationTesting(model, dataloader, config)\n",
    "    \n",
    "    # # Initialize processing modules\n",
    "    embedding_similarity_module = EmbeddingSimilarityModule(model, dataloader, config)\n",
    "\n",
    "    #features, labels =embedding_similarity_module.extract_features()\n",
    "    #embedding_similarity_module.plot_tsne(features,labels)\n",
    "    # cam = ClassActivationMapping(model)\n",
    "\n",
    "    # # Generate test index range\n",
    "    # class_indices = defaultdict(list)\n",
    "    # for idx, (_, label) in enumerate(dataloader.dataset):\n",
    "    #     class_indices[int(label)].append(idx)\n",
    "    # print(class_indices)\n",
    "    # N = 3  # Number of samples per class\n",
    "    # test_index_range = []\n",
    "    # for indices in class_indices.values():\n",
    "    #     if len(indices) >= N:\n",
    "    #         test_index_range.extend(random.sample(indices, N))\n",
    "    #     else:\n",
    "    #         test_index_range.extend(indices)\n",
    "\n",
    "    # # Shuffle the test index range to ensure random order\n",
    "    # random.shuffle(test_index_range)\n",
    "\n",
    "    # Prepare to collect results\n",
    "    test_index_range = [0]\n",
    "    test_results = []\n",
    "\n",
    "    # Run tests on the specific range of indexes\n",
    "    for index in test_index_range:\n",
    "        # Augment the sample\n",
    "        augmentor_sandbox.replace_with_noise(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        aug_sample, aug_label = augmentor_sandbox.get_augmented_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample\n",
    "        model_output = augmentor_sandbox.run_model_on_augmented_sample(aug_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features, es_label = embedding_similarity_module.extract_features(aug_sample, aug_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "        # embedding_similarity_module.plot_tsne(es_features, es_label)\n",
    "\n",
    "        # # Compute class activation mapping\n",
    "        # cam_result = cam.compute(augmented_sample, model_output)\n",
    "        cam_result = None\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"index\": index,\n",
    "            \"output\": model_output,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "\n",
    "    # # # Optionally, save and summarize results\n",
    "    # # save_test_results(test_results)\n",
    "    # print_summary(test_results)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woods_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
