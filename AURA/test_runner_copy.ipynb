{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook of test_runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_CNN1D(\n",
      "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (feature_extractor): ModuleList(\n",
      "    (0): Conv1d(2, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=16000, out_features=256, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",
      "  (logSoftmax): LogSoftmax(dim=1)\n",
      ") cpu\n",
      "cpu\n",
      "(array([[ 0.83196074, -0.65662307,  0.32264539, ..., -0.65761225,\n",
      "        -1.12059288, -0.67295217],\n",
      "       [ 0.50358201,  1.13937468, -0.01223459, ..., -1.17871891,\n",
      "         0.24539864, -0.60937985]]), 3)\n",
      "175800\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from model_loader import load_pretrained_model, load_dataloader\n",
    "from augmentations import DataAugmentationTesting\n",
    "from embeddings_similarity_module import EmbeddingSimilarityModule\n",
    "#from cam_module import ClassActivationMapping\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Create a logger object\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)  # Set the minimum level of messages to log\n",
    "\n",
    "# Create a file handler that logs debug and higher level messages\n",
    "file_handler = logging.FileHandler('example.log', mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Create a console handler that logs debug and higher level messages\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# Add both handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        return json.load(config_file)\n",
    "\n",
    "def save_test_results(test_results, config):\n",
    "    # Fetch the filename from the config dictionary\n",
    "    filename = \"test_results/\"+config[\"test_name\"] + '.pkl'  # Adding .pkl extension to the file name\n",
    "\n",
    "    # Open the file in binary write mode and save the test_results using pickle\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(test_results, file)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "\n",
    "def select_test_idxs(dataloader, num_instances_per_class, all_class_labels):\n",
    "    # Initialize storage for selected indices for each class\n",
    "    class_indices = defaultdict(list)\n",
    "    \n",
    "    # Initialize counters for each class\n",
    "    collected = {label: 0 for label in all_class_labels}  # Ensures we track per label in all_class_labels\n",
    "    \n",
    "    # Track selected indices to avoid duplicates\n",
    "    selected_indices = set()\n",
    "\n",
    "    # Calculate the total number of instances needed\n",
    "    total_needed = num_instances_per_class * len(all_class_labels)\n",
    "\n",
    "    # Iterate until the required number of indices per class is collected\n",
    "    while sum(collected.values()) < total_needed:\n",
    "        idx = random.randint(0, len(dataloader.dataset) - 1)\n",
    "        if idx in selected_indices:\n",
    "            continue\n",
    "        \n",
    "        # Fetch the label, assuming it is accessible and in correct format directly\n",
    "        _, label = dataloader.dataset[idx]\n",
    "        \n",
    "        # Check if more instances are needed for this class\n",
    "        if collected[label] < num_instances_per_class:\n",
    "            class_indices[label].append(idx)\n",
    "            selected_indices.add(idx)\n",
    "            collected[label] += 1\n",
    "\n",
    "        # Verify if all quotas are met to potentially break the loop\n",
    "        if all(count == num_instances_per_class for count in collected.values()):\n",
    "            break\n",
    "\n",
    "    # Flatten the dictionary into a list of indices\n",
    "    test_idxs = [idx for indices in class_indices.values() for idx in indices]\n",
    "\n",
    "    return test_idxs\n",
    "\n",
    "\n",
    "def print_summary(test_results):\n",
    "    \"\"\"\n",
    "    Print summary statistics for test results including accuracy,\n",
    "    precision, recall, and counts of TP, TN, FP, FN for multi-class classification.\n",
    "    \"\"\"\n",
    "    # Initialize counters and accumulators\n",
    "    total_tests = len(test_results)\n",
    "    num_classes = len(test_results[0][\"output_aug\"][0])\n",
    "\n",
    "    aug_correct_predictions = 0\n",
    "    og_correct_predictions = 0\n",
    "    aug_confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    og_confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    for result in test_results:\n",
    "        # Convert model output \n",
    "        og_output_prob = F.softmax(torch.tensor(result[\"output_og\"]), dim=-1).numpy()\n",
    "        og_prediction = np.argmax(og_output_prob)\n",
    "        true_label = result[\"og_label\"]\n",
    "        \n",
    "        # Increment correct predictions\n",
    "        if og_prediction == true_label:\n",
    "            og_correct_predictions += 1\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        og_confusion_matrix[true_label, og_prediction] += 1\n",
    "\n",
    "\n",
    "        # Convert model output \n",
    "        aug_output_prob = F.softmax(torch.tensor(result[\"output_aug\"]), dim=-1).numpy()\n",
    "        aug_prediction = np.argmax(aug_output_prob)\n",
    "        true_label = result[\"og_label\"]\n",
    "        \n",
    "        # Increment correct predictions\n",
    "        if aug_prediction == true_label:\n",
    "            aug_correct_predictions += 1\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        aug_confusion_matrix[true_label, aug_prediction] += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    aug_accuracy = (aug_correct_predictions / total_tests) * 100 if total_tests > 0 else 0\n",
    "    og_accuracy = (og_correct_predictions / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "    # Calculate precision and recall for each class\n",
    "    precision = np.diag(aug_confusion_matrix) / np.sum(aug_confusion_matrix, axis=0)\n",
    "    recall = np.diag(aug_confusion_matrix) / np.sum(aug_confusion_matrix, axis=1)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Total number of test results: {total_tests}\")\n",
    "    print(f\"Model Accuracy on original: {og_accuracy:.2f}%\")\n",
    "    print(f\"Model Accuracy on augmentation: {aug_accuracy:.2f}%\")\n",
    "    for i in range(len(precision)):\n",
    "        TP = aug_confusion_matrix[i, i]\n",
    "        FP = np.sum(aug_confusion_matrix[:, i]) - TP\n",
    "        FN = np.sum(aug_confusion_matrix[i, :]) - TP\n",
    "        TN = np.sum(aug_confusion_matrix) - (TP + FP + FN)\n",
    "        print(f\"Augmented Class {i} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "\n",
    "    # Optionally, print the confusion matrix\n",
    "    print(\"Aug Confusion Matrix:\")\n",
    "    print(aug_confusion_matrix)\n",
    "    print(\"Original Confusion Matrix:\")\n",
    "    print(og_confusion_matrix)\n",
    "\n",
    "    \n",
    "\n",
    "#***************************************************      Main           *************************************************************\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    config_path = \"config.json\"\n",
    "    config = load_config(config_path)\n",
    "    model = load_pretrained_model(config)\n",
    "    logging.info(\"Model Loaded\")\n",
    "\n",
    "    dataloader = load_dataloader(config)\n",
    "    logging.info(\"Dataloader Loaded\")\n",
    "\n",
    "    all_class_labels = [0,1,2,3] # needs to match your dataloader labels\n",
    "    num_instances_per_class = config[\"num_instances_per_class\"]\n",
    "    print(len(dataloader.dataset))\n",
    "    if num_instances_per_class > len(dataloader.dataset)/len(all_class_labels):\n",
    "        raise ValueError(\"num_instances_per_class is greater than test dataset size/ num classes. Please reduce test size in config.\")\n",
    "    test_index_list = select_test_idxs(dataloader, num_instances_per_class,all_class_labels)\n",
    "    logging.info(\"Test list created and Loaded\")\n",
    "    #print(test_index_list)\n",
    "\n",
    "    # Initialize the Data Augmentation Module\n",
    "    augmentor_sandbox = DataAugmentationTesting(model, dataloader, config)\n",
    "    \n",
    "    # # Initialize processing modules\n",
    "    embedding_similarity_module = EmbeddingSimilarityModule(model, dataloader, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing indexes: 100%|██████████| 400/400 [00:06<00:00, 61.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results saved to test_results/awgn_tprime_debug.pkl\n",
      "Total number of test results: 400\n",
      "Model Accuracy on original: 100.00%\n",
      "Model Accuracy on augmentation: 25.00%\n",
      "Augmented Class 0 - Precision: 0.2500, Recall: 1.0000, TP: 100, TN: 0, FP: 300, FN: 0\n",
      "Augmented Class 1 - Precision: nan, Recall: 0.0000, TP: 0, TN: 300, FP: 0, FN: 100\n",
      "Augmented Class 2 - Precision: nan, Recall: 0.0000, TP: 0, TN: 300, FP: 0, FN: 100\n",
      "Augmented Class 3 - Precision: nan, Recall: 0.0000, TP: 0, TN: 300, FP: 0, FN: 100\n",
      "Aug Confusion Matrix:\n",
      "[[100   0   0   0]\n",
      " [100   0   0   0]\n",
      " [100   0   0   0]\n",
      " [100   0   0   0]]\n",
      "Original Confusion Matrix:\n",
      "[[100   0   0   0]\n",
      " [  0 100   0   0]\n",
      " [  0   0 100   0]\n",
      " [  0   0   0 100]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_1442852/1796738631.py:134: RuntimeWarning: invalid value encountered in divide\n",
      "  precision = np.diag(aug_confusion_matrix) / np.sum(aug_confusion_matrix, axis=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare to collect results\n",
    "test_results = []\n",
    "\n",
    "# Run tests on the specific range of indexes\n",
    "for index in tqdm(test_index_list, desc=\"Processing indexes\"):\n",
    "\n",
    "    # Check if SNR reduction test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"noise\"][\"enable_test\"]:\n",
    "        #Run AWGN Aug Test *************************************\n",
    "        # Augment the sample\n",
    "        augmentor_sandbox.replace_with_noise(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        awgn_aug_sample, aug_label = augmentor_sandbox.awgn_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(awgn_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(awgn_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "        # embedding_similarity_module.plot_tsne(es_features, es_label)\n",
    "        # # # Compute class activation mapping\n",
    "        # cam_result = cam.compute(augmented_sample, model_output)\n",
    "        cam_result = None\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"awgn\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\":es_features_og,\n",
    "            \"embedding_features_aug\":es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end awgn aug datatest *****************************\n",
    "\n",
    "    # Check if test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"CFO\"][\"enable_test\"]:\n",
    "        #Run CFO Aug Test *************************************\n",
    "        # Augment the sample (creates new augmented cfo dataset as well)\n",
    "        augmentor_sandbox.add_frequency_offset(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        cfo_aug_sample, aug_label = augmentor_sandbox.cfo_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(cfo_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "        #print(output_og)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(cfo_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "        # embedding_similarity_module.plot_tsne(es_features, es_label)\n",
    "\n",
    "        # # Compute class activation mapping\n",
    "        # cam_result = cam.compute(augmented_sample, model_output)\n",
    "        cam_result = None\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"cfo\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\":es_features_og,\n",
    "            \"embedding_features_aug\":es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "    #**************** end CFO aug datatest *****************************\n",
    "\n",
    "    # Check if SNR reduction test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"SNR\"][\"enable_test\"]:\n",
    "        # Run SNR Reduction Test *************************************\n",
    "        # Augment the sample (creates new augmented snr dataset as well)\n",
    "        augmentor_sandbox.reduce_SNR(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        snr_aug_sample, aug_label = augmentor_sandbox.snr_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(snr_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(snr_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        # embedding_similarity_module.plot_tsne(\n",
    "        #     es_features_og, es_features_aug, og_label, aug_label, test_type=\"SNR Test\"\n",
    "        # )\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"snr\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end SNR reduction test *****************************\n",
    "\n",
    "    if config[\"augmentation_test_params\"][\"FSPL\"][\"enable_test\"]:\n",
    "        # Run FSPL Test *************************************\n",
    "        # Augment the sample (creates new augmented fspl dataset as well)\n",
    "        augmentor_sandbox.apply_FSPL(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        fspl_aug_sample, aug_label = augmentor_sandbox.fspl_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(fspl_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(fspl_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder for CAM computation\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"fspl\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end FSPL test *****************************\n",
    "    \n",
    "    if config[\"augmentation_test_params\"][\"phase_rotation\"][\"enable_test\"]:\n",
    "        # Run Phase Rotation Test *************************************\n",
    "        # Augment the sample (creates new augmented phase rotation dataset as well)\n",
    "        augmentor_sandbox.apply_phase_rotation(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        phase_rot_aug_sample, aug_label = augmentor_sandbox.phase_rot_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(phase_rot_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(phase_rot_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder for CAM computation\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"phase_rotation\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end Phase Rotation test *****************************\n",
    "    \n",
    "    # Check if IQ imbalance test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"IQ_imbalance\"][\"enable_test\"]:\n",
    "        # Run IQ Imbalance Test *************************************\n",
    "        # Augment the sample (creates new augmented IQ imbalance dataset as well)\n",
    "        augmentor_sandbox.apply_IQ_imbalance(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        iq_aug_sample, aug_label = augmentor_sandbox.iq_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(iq_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        # Assuming `embedding_similarity_module` is set up to extract features and compute similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(iq_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 # Placeholder for actual similarity computation, implement as needed\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder for CAM computation, assuming `cam` is set up to compute this\n",
    "        # cam_result = cam.compute(iq_aug_sample, output_aug) - if CAM computation is defined\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"IQ_imbalance\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end IQ Imbalance test *****************************\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# # Optionally, save and summarize results\n",
    "save_test_results(test_results, config)\n",
    "print_summary(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_plot_tsne(test_results, selected_tests=None, indexes_to_plot=None):\n",
    "    \"\"\"\n",
    "    Aggregates test results and plots t-SNE for selected tests.\n",
    "\n",
    "    :param test_results: List of dictionaries containing test outputs.\n",
    "    :param selected_tests: List of test types to plot. If None, plots all tests.\n",
    "    :param indexes_to_plot: List of specific indexes to plot for augmented data; plots all if None.\n",
    "    \"\"\"\n",
    "    test_data = {}\n",
    "\n",
    "    # Aggregate data\n",
    "    for i, result in enumerate(test_results):\n",
    "        test_type = result['test']\n",
    "        \n",
    "        # Continue only if test_type is in the selected_tests or if selected_tests is None\n",
    "        if selected_tests is not None and test_type not in selected_tests:\n",
    "            continue\n",
    "\n",
    "        if test_type not in test_data:\n",
    "            test_data[test_type] = {'features_og': [], 'features_aug': [], 'labels_og': [], 'labels_aug': []}\n",
    "\n",
    "        # Always include original features and labels, ensure labels are numpy arrays\n",
    "        test_data[test_type]['features_og'].append(result['embedding_features_og'])\n",
    "        test_data[test_type]['labels_og'].append(np.array([result['og_label']]))\n",
    "\n",
    "        # Include augmented features and labels based on specific indexes, if provided\n",
    "        if indexes_to_plot is None or i in indexes_to_plot:\n",
    "            test_data[test_type]['features_aug'].append(result['embedding_features_aug'])\n",
    "            test_data[test_type]['labels_aug'].append(np.array([result['aug_label']]))\n",
    "\n",
    "    # Plot data\n",
    "    for test, data in test_data.items():\n",
    "        if data['features_og']:  # Ensure there are original features to plot\n",
    "            features_og = np.concatenate(data['features_og'], axis=0)\n",
    "            labels_og = np.concatenate(data['labels_og'])\n",
    "            print(np.unique(labels_og))\n",
    "            num_original = len(data['features_og'])\n",
    "        else:\n",
    "            raise ValueError(\"no features to plot selected\")\n",
    "\n",
    "        if data['features_aug']:  # Check if there are any augmented features to plot\n",
    "            features_aug = np.concatenate(data['features_aug'], axis=0)\n",
    "            labels_aug = np.concatenate(data['labels_aug'])\n",
    "\n",
    "        else:\n",
    "            features_aug = np.array([])\n",
    "            labels_aug = np.array([])\n",
    "\n",
    "        all_features = np.vstack((features_og, features_aug)) if features_aug.size else features_og\n",
    "        all_labels = np.concatenate((labels_og, labels_aug)) if labels_aug.size else labels_og\n",
    "        print(np.unique(all_labels))\n",
    "        embedding_similarity_module.plot_tsne(all_features, all_labels, num_original, test)\n",
    "\n",
    "\n",
    "# aggregate_and_plot_tsne(test_results, selected_tests=['snr'], indexes_to_plot=[1])\n",
    "aggregate_and_plot_tsne(test_results, selected_tests=['awgn'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woods_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
