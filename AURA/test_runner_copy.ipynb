{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook of test_runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from model_loader import load_pretrained_model, load_dataloader\n",
    "from augmentations import DataAugmentationTesting\n",
    "from embeddings_similarity_module import EmbeddingSimilarityModule\n",
    "#from cam_module import ClassActivationMapping\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Create a logger object\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)  # Set the minimum level of messages to log\n",
    "\n",
    "# Create a file handler that logs debug and higher level messages\n",
    "file_handler = logging.FileHandler('example.log', mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(file_formatter)\n",
    "\n",
    "# Create a console handler that logs debug and higher level messages\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.DEBUG)\n",
    "console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_formatter)\n",
    "\n",
    "# Add both handlers to the logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        return json.load(config_file)\n",
    "\n",
    "def save_test_results(test_results, config):\n",
    "    # Fetch the filename from the config dictionary\n",
    "    filename = \"test_results/\"+config[\"test_name\"] + '.pkl'  # Adding .pkl extension to the file name\n",
    "\n",
    "    # Open the file in binary write mode and save the test_results using pickle\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(test_results, file)\n",
    "\n",
    "    print(f\"Test results saved to {filename}\")\n",
    "\n",
    "def select_test_idxs(dataloader, num_instances_per_class, all_class_labels):\n",
    "    # Initialize storage for selected indices for each class\n",
    "    class_indices = defaultdict(list)\n",
    "    \n",
    "    # Initialize counters for each class\n",
    "    collected = {label: 0 for label in all_class_labels}  # Ensures we track per label in all_class_labels\n",
    "    \n",
    "    # Track selected indices to avoid duplicates\n",
    "    selected_indices = set()\n",
    "\n",
    "    # Calculate the total number of instances needed\n",
    "    total_needed = num_instances_per_class * len(all_class_labels)\n",
    "\n",
    "    # Iterate until the required number of indices per class is collected\n",
    "    while sum(collected.values()) < total_needed:\n",
    "        idx = random.randint(0, len(dataloader.dataset) - 1)\n",
    "        if idx in selected_indices:\n",
    "            continue\n",
    "        \n",
    "        # Fetch the label, assuming it is accessible and in correct format directly\n",
    "        _, label = dataloader.dataset[idx]\n",
    "        \n",
    "        # Check if more instances are needed for this class\n",
    "        if collected[label] < num_instances_per_class:\n",
    "            class_indices[label].append(idx)\n",
    "            selected_indices.add(idx)\n",
    "            collected[label] += 1\n",
    "\n",
    "        # Verify if all quotas are met to potentially break the loop\n",
    "        if all(count == num_instances_per_class for count in collected.values()):\n",
    "            break\n",
    "\n",
    "    # Flatten the dictionary into a list of indices\n",
    "    test_idxs = [idx for indices in class_indices.values() for idx in indices]\n",
    "\n",
    "    return test_idxs\n",
    "\n",
    "\n",
    "def print_summary(test_results):\n",
    "    \"\"\"\n",
    "    Print summary statistics for test results including accuracy,\n",
    "    precision, recall, and counts of TP, TN, FP, FN for multi-class classification.\n",
    "    \"\"\"\n",
    "    # Initialize counters and accumulators\n",
    "    total_tests = len(test_results)\n",
    "    num_classes = len(test_results[0][\"output_aug\"][0])\n",
    "\n",
    "    aug_correct_predictions = 0\n",
    "    og_correct_predictions = 0\n",
    "    aug_confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    og_confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    for result in test_results:\n",
    "        # Convert model output \n",
    "        og_output_prob = F.softmax(torch.tensor(result[\"output_og\"]), dim=-1).numpy()\n",
    "        og_prediction = np.argmax(og_output_prob)\n",
    "        true_label = result[\"og_label\"]\n",
    "        \n",
    "        # Increment correct predictions\n",
    "        if og_prediction == true_label:\n",
    "            og_correct_predictions += 1\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        og_confusion_matrix[true_label, og_prediction] += 1\n",
    "\n",
    "\n",
    "        # Convert model output \n",
    "        aug_output_prob = F.softmax(torch.tensor(result[\"output_aug\"]), dim=-1).numpy()\n",
    "        aug_prediction = np.argmax(aug_output_prob)\n",
    "        true_label = result[\"og_label\"]\n",
    "        \n",
    "        # Increment correct predictions\n",
    "        if aug_prediction == true_label:\n",
    "            aug_correct_predictions += 1\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        aug_confusion_matrix[true_label, aug_prediction] += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    aug_accuracy = (aug_correct_predictions / total_tests) * 100 if total_tests > 0 else 0\n",
    "    og_accuracy = (og_correct_predictions / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "    # Calculate precision and recall for each class\n",
    "    precision = np.diag(aug_confusion_matrix) / np.sum(aug_confusion_matrix, axis=0)\n",
    "    recall = np.diag(aug_confusion_matrix) / np.sum(aug_confusion_matrix, axis=1)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"Total number of test results: {total_tests}\")\n",
    "    print(f\"Model Accuracy on original: {og_accuracy:.2f}%\")\n",
    "    print(f\"Model Accuracy on augmentation: {aug_accuracy:.2f}%\")\n",
    "    for i in range(len(precision)):\n",
    "        TP = aug_confusion_matrix[i, i]\n",
    "        FP = np.sum(aug_confusion_matrix[:, i]) - TP\n",
    "        FN = np.sum(aug_confusion_matrix[i, :]) - TP\n",
    "        TN = np.sum(aug_confusion_matrix) - (TP + FP + FN)\n",
    "        print(f\"Augmented Class {i} - Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "\n",
    "    # Optionally, print the confusion matrix\n",
    "    print(\"Aug Confusion Matrix:\")\n",
    "    print(aug_confusion_matrix)\n",
    "    print(\"Original Confusion Matrix:\")\n",
    "    print(og_confusion_matrix)\n",
    "\n",
    "    \n",
    "\n",
    "#***************************************************      Main           *************************************************************\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    config_path = \"config.json\"\n",
    "    config = load_config(config_path)\n",
    "    model = load_pretrained_model(config)\n",
    "    logging.info(\"Model Loaded\")\n",
    "\n",
    "    dataloader = load_dataloader(config)\n",
    "    logging.info(\"Dataloader Loaded\")\n",
    "\n",
    "    all_class_labels = [0,1,2,3] # needs to match your dataloader labels\n",
    "    num_instances_per_class = config[\"num_instances_per_class\"]\n",
    "    print(len(dataloader.dataset))\n",
    "    if num_instances_per_class > len(dataloader.dataset)/len(all_class_labels):\n",
    "        raise ValueError(\"num_instances_per_class is greater than test dataset size/ num classes. Please reduce test size in config.\")\n",
    "    test_index_list = select_test_idxs(dataloader, num_instances_per_class,all_class_labels)\n",
    "    logging.info(\"Test list created and Loaded\")\n",
    "    #print(test_index_list)\n",
    "\n",
    "    # Initialize the Data Augmentation Module\n",
    "    augmentor_sandbox = DataAugmentationTesting(model, dataloader, config)\n",
    "    \n",
    "    # # Initialize processing modules\n",
    "    embedding_similarity_module = EmbeddingSimilarityModule(model, dataloader, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare to collect results\n",
    "test_results = []\n",
    "\n",
    "# Run tests on the specific range of indexes\n",
    "for index in tqdm(test_index_list, desc=\"Processing indexes\"):\n",
    "\n",
    "    # Check if SNR reduction test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"noise\"][\"enable_test\"]:\n",
    "        #Run AWGN Aug Test *************************************\n",
    "        # Augment the sample\n",
    "        augmentor_sandbox.replace_with_noise(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        awgn_aug_sample, aug_label = augmentor_sandbox.awgn_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(awgn_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(awgn_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "        # embedding_similarity_module.plot_tsne(es_features, es_label)\n",
    "        # # # Compute class activation mapping\n",
    "        # cam_result = cam.compute(augmented_sample, model_output)\n",
    "        cam_result = None\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"awgn\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\":es_features_og,\n",
    "            \"embedding_features_aug\":es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end awgn aug datatest *****************************\n",
    "\n",
    "    # Check if test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"CFO\"][\"enable_test\"]:\n",
    "        #Run CFO Aug Test *************************************\n",
    "        # Augment the sample (creates new augmented cfo dataset as well)\n",
    "        augmentor_sandbox.add_frequency_offset(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        cfo_aug_sample, aug_label = augmentor_sandbox.cfo_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(cfo_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "        #print(output_og)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(cfo_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "        # embedding_similarity_module.plot_tsne(es_features, es_label)\n",
    "\n",
    "        # # Compute class activation mapping\n",
    "        # cam_result = cam.compute(augmented_sample, model_output)\n",
    "        cam_result = None\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"cfo\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\":es_features_og,\n",
    "            \"embedding_features_aug\":es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "    #**************** end CFO aug datatest *****************************\n",
    "\n",
    "    # Check if SNR reduction test is enabled\n",
    "    if config[\"augmentation_test_params\"][\"SNR\"][\"enable_test\"]:\n",
    "        # Run SNR Reduction Test *************************************\n",
    "        # Augment the sample (creates new augmented snr dataset as well)\n",
    "        augmentor_sandbox.reduce_SNR(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        snr_aug_sample, aug_label = augmentor_sandbox.snr_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(snr_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(snr_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"snr\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end SNR reduction test *****************************\n",
    "\n",
    "    if config[\"augmentation_test_params\"][\"FSPL\"][\"enable_test\"]:\n",
    "        # Run FSPL Test *************************************\n",
    "        # Augment the sample (creates new augmented fspl dataset as well)\n",
    "        augmentor_sandbox.apply_FSPL(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        fspl_aug_sample, aug_label = augmentor_sandbox.fspl_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(fspl_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(fspl_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder for CAM computation\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"fspl\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end FSPL test *****************************\n",
    "    \n",
    "    if config[\"augmentation_test_params\"][\"phase_rotation\"][\"enable_test\"]:\n",
    "        # Run Phase Rotation Test *************************************\n",
    "        # Augment the sample (creates new augmented phase rotation dataset as well)\n",
    "        augmentor_sandbox.apply_phase_rotation(index)\n",
    "\n",
    "        # Get the augmented sample\n",
    "        phase_rot_aug_sample, aug_label = augmentor_sandbox.phase_rot_aug_data.__getitem__(index)\n",
    "        og_sample, og_label = augmentor_sandbox.get_original_sample(index)\n",
    "\n",
    "        # Run model inference on augmented sample and original\n",
    "        output_aug = augmentor_sandbox.run_model_on_sample(phase_rot_aug_sample)\n",
    "        output_og = augmentor_sandbox.run_model_on_sample(og_sample)\n",
    "\n",
    "        # Compute embedding similarity\n",
    "        es_features_aug, es_label_aug = embedding_similarity_module.extract_features(phase_rot_aug_sample, aug_label)\n",
    "        es_features_og, es_label_og = embedding_similarity_module.extract_features(og_sample, og_label)\n",
    "        es_result = 0 #TODO compute distance metric for similarity\n",
    "\n",
    "        # Compute class activation mapping\n",
    "        cam_result = None  # Placeholder for CAM computation\n",
    "\n",
    "        # Store results\n",
    "        test_results.append({\n",
    "            \"test\": \"phase_rotation\",\n",
    "            \"index\": index,\n",
    "            \"og_label\": og_label,\n",
    "            \"aug_label\": aug_label,\n",
    "            \"output_og\": output_og,\n",
    "            \"output_aug\": output_aug,\n",
    "            \"embedding_similarity\": es_result,\n",
    "            \"embedding_features_og\": es_features_og,\n",
    "            \"embedding_features_aug\": es_features_aug,\n",
    "            \"cam_result\": cam_result\n",
    "        })\n",
    "        #**************** end Phase Rotation test *****************************\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# # Optionally, save and summarize results\n",
    "save_test_results(test_results, config)\n",
    "print_summary(test_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woods_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
